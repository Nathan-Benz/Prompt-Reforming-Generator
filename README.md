# Prompt-Reforming-Generator (PRG)
Using Meta's Llama 2 LLM, we fine tune the model to be optimized for turning "bad" prompts that yield an inefficient response into "good" ones which are optimal prompts that generate fruitful responses.

## Authors and Credits
- Julian Sanchez
- Emily Zou
- Nathan Benitez
- Nati Seifu

Additional credits:
- Abraham Bautista (Mentor)
## Vision for the Model
- 
## Dataset
- 
## Packages and Libraries
We used a very strong package in, AutoTrain, to fine-tune the open-source Llama V2 assistant for our purpose.
 - The one-liner code included in the training section is achieved through this package.
 - Usually, a large-scale fine-tuning processes would require a strong GPU, but the small dataset we have allows the fine-tuning at a smaller scale.

## Possible Future Capabilities
<to be filled>

## Resources Used
