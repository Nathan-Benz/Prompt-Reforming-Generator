# Promptimizer
Using Meta's Llama 2 LLM, we fine tune the model to be optimized for turning "bad" prompts that yield an inefficient responses into "good" ones which are optimal prompts specifically for AI that generate fruitful responses.

## Authors and Credits
- Julian Sanchez
- Emily Zou
- Nathan Benitez
- Nati Seifu

Additional credits:
- Abraham Bautista (Mentor)
- [PromptEnginerring](https://youtu.be/LslC2nKEEGU)
- [1littlecoder](https://youtu.be/eeM6V5aPjhk)
## Vision for the Model
- 
## Dataset
- 
## Packages and Libraries
We used a very strong package in, AutoTrain, to fine-tune the open-source Llama V2 assistant for our purpose.
 - The one-liner code included in the training section is achieved through this package.
 - Usually, a large-scale fine-tuning processes would require a strong GPU, but the small dataset we have allows the fine-tuning at a smaller scale.

## Possible Future Capabilities
<to be filled>

## Resources Used
